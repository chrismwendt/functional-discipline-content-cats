%%%%%%%%%%%%%
% Variables %
%%%%%%%%%%%%%

% Language
\setvariables [document] [language=en]

% Version and mode
\setvariables [document] [version=final]    % {final, concept, temporary}
\setvariables [document] [mode=presentation]    % {presentation, manuscript, handout}

% Colors
% https://coolors.co/app
\setvariables [document] [color-link-external=royalblue]
\setvariables [document] [color-link-internal=violetred]
\setvariables [document] [color-background-0=white]
\setvariables [document] [color-background-1=mistyrose]
\setvariables [document] [color-background-2=whitesmoke]
\setvariables [document] [color-foreground-0=deepskyblue4]
\setvariables [document] [color-foreground-1=firebrick4]
\setvariables [document] [color-foreground-2=darkslategray]

% Fonts
% Options: palatino, xitsbidi, euler
\setvariables [document] [font=palatino]
\setvariables [document] [fontsize-presentation=38pt]
\setvariables [document] [fontsize-document=12pt]

% Information
\setvariables [document] [title={An introduction to ItÃ´ calculus and anticipating integrals}]
\setvariables [document] [subtitle={GEAUX presentation}]
\setvariables [document] [author={Sudip Sinha}]
\setvariables [document] [date={2019-08-22}]
\setvariables [document] [keyword={mathematics, probability, stochastic, integral, calculus, large deviations, applications}]

% Logo
\setvariables [document] [logo=MC_Logo_Symbol_672x668.png]

% Environment
\environment env-talks


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is where the document starts.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\starttext

\startfrontmatter

%%%%%%%%%%%%%%%%
% Front matter %
%%%%%%%%%%%%%%%%

\setupbackgrounds [page] [
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-0}]
\startcolor [\getvariable{document}{color-foreground-0}]    % text color


% \startmode [handout]
% \startcolumns
% \stopmode


% Introduction
\startmode [presentation]

\startslide

\startalign [middle]

	{\tfd
		An introduction to ItÃ´ calculus\\
		and anticipating integrals}

	\blank[2*line]

	{\tfb \getvariable{document}{author}}

	\blank[line]

	{\tfa \getvariable{document}{date}}

	\blank[2*line]

	Advisors

	Prof. Hui-Hsiung Kuo

	Prof. Padmanabhan Sundar
\stopalign
\stopslide


% Table of contents
\startslide [title={Outline}]
	\placecontent

\stopslide
\stopmode

% \startmode [manuscript]

% This presentation is going to be on two topics:
% \startitemize[n,nowhite,after]
% 	\item  Generalization of stochastic integrals developed primarily by Professor H.-H. Kuo
% 	\item  Applications of generalization in large deviations theory
% \stopitemize

% \stopmode

\stopfrontmatter



\startbodymatter

\setupbackgrounds [page] [
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-0}]
\startcolor [\getvariable{document}{color-foreground-0}]    % text color

\startsection [title={Introduction to the Theory}, reference=sec:theory]

\startmode [presentation]

\startslide [title={Axiomatic probability theory}]
	
	\startdefinition
		A \important{probability space} is a triple \m{(Î©, â„±, â„™)}, where
		\startitemize [4, joinedup]
			\item  \m{Î©} is a set containing the elementary outcomes.
			\item  \m{â„± âŠ† 2^Î©} is a Ïƒ-algebra on \m{Î©}, i.e.
				\startitemize [5, joinedup]
					\item  \m{âˆ… âˆˆ â„±},
					\item  \m{E âˆˆ â„±} âŸ¹ \m{E^âˆ âˆˆ â„±}, and
					\item  \m{(E_n)_{n âˆˆ â„•} âŠ‚ â„±} âŸ¹ \m{â‹ƒ E_n âˆˆ â„±}.
				\stopitemize

			\item  \m{â„™: â„± â†’ [0, 1]} is the probability measure on the measurable space \m{(Î©, â„±)}, i.e.
				\startitemize [5, joinedup]
					\item  \m{â„™(âˆ…) = 0},
					\item  (Ïƒ-additivity) For every disjoint sequence of sets \m{(E_n)_{n âˆˆ â„•} âŠ‚ â„±}, \m{â„™(â¨† E_n) = âˆ‘ P(E_n)}, and
					\item  (\emph{probability} measure) \m{â„™(Î©) = 1}.
				\stopitemize
		\stopitemize
	\stopdefinition

	\bold{Remarks}
	\startitemize [m, joinedup]
		Elements of \m{â„±} (sets) are the \emph{events} to which we can assign a \emph{probability} in a meaningful way.
		
		Thus, the Ïƒ-algebra represents \quotation{information} in the system.
	
		The finer the Ïƒ-algebra, the more information we have.
	\stopitemize
\stopslide

\startslide [title={Martingales}]
	
	\startitemize [4]
		
		\item  A \important{random variable} is a \m{â„±}-\emph{measurable} function \m{X: Î© â†’ â„}.
		
		\item  A \important{stochastic process} is a \emph{parameterized family} of random variables \m{(X_t)_{t âˆˆ [0, T]}} defined on a probability space \m{(Î©, â„±, â„™)} and assuming values in \m{â„}.

			\comment{We usually think of \m{t} as time and \m{(X_t)} as the process evolving in time.}

		\item  A \important{filtration} is an increasing \emph{parameterized family} \m{(â„±_t)_{t âˆˆ [0, T]}} of Ïƒ-algebras.

			\comment{We think of the system evolving in time, so it has more information as time passes.}

		\item  Let \m{0 â‰¤ s â‰¤ t â‰¤ T}. Then a stochastic process \m{(X_t)} is called a \important{martingale} if \m{ğ”¼(X_t âˆ£ â„±_s) = X_s}.

			\comment{Martingales represent \emph{fair games}.}

			Example: A fair coin is tossed at each unit of time. I win 1\$ if heads turn up and lose 1\$ when tails turn up. Then my wealth is a martingale, because at any point in time my conditional expected fortune after the next trial, given the history, is equal to their present fortune.

		\item  A stochastic process \m{(X_t)} is called \important{adapted} to the filtration \m{(â„±_t)_t} if \m{X_t} is \m{â„±_t}-measurable \m{âˆ€t}.
	\stopitemize
\stopslide

\startslide [title={Brownian motions in one dimension}]
	\placefigure[fit]{}{\externalfigure[Brownian_motion.png][height=0.7\textheight]}
\stopslide

\startslide [title={Brownian motion}]
	
	\startitemize [m]
	
		\item  A \important{Brownian motion} \m{(B_t)_{t âˆˆ [0, T]}} is a stochastic process which has the following properties:
			\startitemize [m, joinedup]
				\item  Starts at 0 (a.s.)
				\item  Has independent increments
				\item  \m{B_t - B_s âˆ¼ ğ“(0, t - s)}
				\item  Has continuous sample paths (a.s.)
			\stopitemize

		\item  Other properties of Brownian motion \m{(B_t)}
			\startitemize [m, joinedup]
				\item  It is a.s. nowhere differentiable
				\item  \bad{It has unbounded linear variation \frown, so naive integration w.r.t. \m{B_t} is not possible}
				\item  \good{It has bounded quadratic variation \smile}
				% \item  \m{ğ”¼(B_t B_s) = s âˆ§ t}
				\item  \m{(B_t)} a martingale
				\item  \m{(B_t^2 - t)} is a martingale
				% \item  Is a Markov process
			\stopitemize
	\stopitemize
\stopslide



\startsection [title={ItÃ´ calculus}, reference=sec:ItÃ´]
\startmode [presentation]

\startslide [title={Trying to integrate stochastic processes}]

	\startitemize [4]

		\item  Question: \m{âˆ«_0^T B_t \d B_t â‰Ÿ}

			Since \m{B_t} is continuous, let us try the Riemannâ€“Stieltjes integral. Consider a sequence of partitions \m{Î”_n} such that \m{\norm[Î”_n] â†’ 0}. We denote \m{Î” B_j = B_{t_{j + 1}} - B_{t_j}}. Then
			\startformula
				âˆ«_0^T B_t \d B_t  =  \lim âˆ‘_{j = 0}^{n - 1} B_{t_j^*} Î” B_j .
			\stopformula

		\item  Choosing different endpoints for \m{t_j^*} gives us different results.
			\starttabulate [|c|m|c|m|c|c|]
				\NC  \m{t_j^*}  \NC  âˆ«_0^t B_s \d B_s  \NC  Intuitive?  \NC  ğ”¼  \NC  Martingale?  \NC  Theory  \NR
				\FL
				\NC  \good{left}   \NC  \good{\frac12 \brnd[B_t^2 - t]}  \NC  \good{\frown}  \NC  \good{0}  \NC  \good{\smile}  \NC  \good{ItÃ´}  \NR
				\NC  mid    \NC  \frac12 \brnd[B_t^2]  \NC  \smile  \NC  \frac12 t  \NC  \frown  \NC  Stratonovich  \NR
				\NC  \bad{right}  \NC  \bad{\frac12 \brnd[B_t^2 + t]}  \NC  \bad{\frown}  \NC  \bad{t}  \NC  \bad{\frown}  \NC    \NR
				\BL
			\stoptabulate

		\item  Which one do we choose?
	\stopitemize
\stopslide

\startslide [title={ItÃ´ integral \cite[short][ItÃ´1944SI] for \m{(X_t)} with continuous paths}]

	\startitemize [4]

		\item  Definition of the integral: \m{âˆ«_0^T X_t \d B_t  =  \lim âˆ‘_{j = 0}^{n - 1} X_{t_j} Î” B_j}.

		\item  Properties of the integral:
			\startitemize [5, joinedup]
				\item  Linear.
				\item  Mean 0 and variance \m{\norm[f]_{L^2[0, T]}^2} \good{(ItÃ´ isometry)}.
			\stopitemize

		\item  Properties of the associated process \m{I_{\argdotsub} = âˆ«_0^{\argdotsup} X_t \d B_t}:
			\startitemize [5, joinedup]
				\item  continuity
				\item  martingale
			\stopitemize

		\item  Example: \m{âˆ«_0^t B_u \d B_u = \frac12 (B_t^2 - t) \quad âˆ€ t}.

		\item  Remark: We can only integrate over processes which are adapted.

	\stopitemize
\stopslide

\startslide [title={Multiple integrals}]

	\startitemize [4]

		\item  Question: How do we define the double integral?

		\item  Naive idea: \m{âˆ«_0^t âˆ«_0^t \d B_u \d B_v = âˆ«_0^t \d B_u âˆ«_0^t \d B_v = B_t^2}.

			But \m{ğ”¼ B_t^2 = \ugly{t â‰  0}}, so \ugly{no martingale property}. \frown

		\item  ItÃ´'s idea: remove the diagonal to get
		\startformula
			âˆ«_0^t âˆ«_0^t \d B_u \d B_v  =  2 âˆ«_0^t âˆ«_0^v \d B_u \d B_v  =  2 âˆ«_0^t B_v \d B_v  =  B_t^2 - t .
		\stopformula
	\stopitemize

	\starttheorem[title={\cite[short][ItÃ´1951MWI]}]
		Let \m{f âˆˆ L^2\brnd[{[0, T]}^n]} and \m{\bad{\hat{f}}} be its symmetrization. Then
		\startformula
			âˆ«_{[0, T]^n} f(t_1, â€¦, t_n) \d B_{t_1} â‹¯ \d B_{t_n}  =  \bad{n!} âˆ«_0^T â‹¯ âˆ«_0^{\bad{t_{n-2}}} \brnd[âˆ«_0^{\bad{t_{n-1}}} \bad{\hat{f}}(t_1, â€¦, t_n) \d B_{t_n}] \d B_{t_{n-1}} â‹¯ \d B_{t_1} .
		\stopformula
		% \m{\hat{f}(t_1, â€¦, t_n)  =  \frac{1}{n!} âˆ‘_{Ïƒ âˆˆ S_n} f(t_{Ïƒ(1)}, â€¦, t_{Ïƒ(n)})}
	\stoptheorem

	\startitemize [4]
		\item  Feels non-intuitive \frown.
	\stopitemize
\stopslide

\stopmode

\stopsection


\startsection [title={A Generalization of ItÃ´ calculus}, reference=sec:beyond-ItÃ´]

\startmode [presentation]

\startslide [title={Motivation}]

	\startitemize [4]

		\item  Iterated integrals: Consider the iterated integral \m{âˆ«_0^t âˆ«_0^t \d B_u \d B_v \ugly{= âˆ«_0^t B_t \d B_v â‰Ÿ B_t^2}}.

		\item  Note that \m{ğ”¼(B_t^2) = \ugly{t â‰  0}}, so \ugly{no martingale property} \frown.

		% \item  Stochastic differential equations with anticipation:
		% 	% \startitemize [5, joinedup]
		% 	% 	\item  \m{\d X_t  =  X_t \d B_t, X_0 = B_T}
		% 	% 	\item  \m{\d Y_t  =  B_T \d B_t, Y_0 = 1}
		% 	% \stopitemize
		% \startformula \startalign[m=2, distance=8em, align={right, left, right, left}]
		% 	\NC  \d X_t  \NC =  X_t \d B_t
		% 	\NC  \d Y_t  \NC =  B_T \d B_t
		% 	\NR
		% 	\NC  X_0  \NC =  B_T
		% 	\NC  Y_0  \NC =  1
		% \stopalign \stopformula

		\item  Problem: We want to define \m{âˆ«_0^T Z(\argdotmid) \d B_t}, where \m{Z(\argdotmid)} is not (necessarily) adapted.

		\item  Some approaches:
		\startitemize [5, joinedup]
			\item  Enlargement of filtration \m{ğ“–_{\argdotsub} = ğ“•_{\argdotsub} âˆ¨ Ïƒ(B_T)}, with ItÃ´'s decomposition of integrand \cite[short][ItÃ´1978] \m{B_t = \brnd[B_t - âˆ«_0^t \frac{B_T - B_s}{T - s} \d s] + âˆ«_0^t \frac{B_T - B_s}{T - s} \d s}.
			\item  White noise theory
			\item  Malliavin calculus
			% \item  â€¦

				% \m{B_t = \brnd[B_t - âˆ«_0^t \frac{B_T - B_s}{1 - s} \d s] + âˆ«_0^T \frac{B_T - B_s}{1 - s} \d s}
		\stopitemize

	\stopitemize
\stopslide

\startslide [title={The new integral \cite[short][AyedKuo2008, AyedKuo2010]}: Idea]

	\startitemize[1]

		\item  A process \m{Y^{\argdotsup}} and filtration \m{â„±_{\argdotsub}} are called \important{instantly independent} if \m{Y^t} and \m{â„±_t} are independent \m{âˆ€ t}.

			Example: The process \m{(B_T - B_{\argdotsub})} is instantly independent of the filtration generated by \m{B_{\argdotsub}}.

		\item  Idea
			\startitemize[n, joinedup]

				\item  Decompose the integrand into \good{adapted} and \okay{instantly independent} parts.

				\item  Evaluate the \good{adapted} and the \okay{instantly independent} parts at the \good{left} and \okay{right} endpoints.

			\stopitemize

		\item  Consider two continuous stochastic processes, \good{\m{X_t} adapted} and \okay{\m{Y^t} instantly independent} w.r.t. \m{â„±_{\argdotsub}}. Then the integral \m{âˆ«_0^T \good{X_t} \okay{Y^t} \d B_t} is \important{defined} as
			\startformula
				âˆ«_0^T \good{X_t} \okay{Y^t} \d B_t  â‰œ  \lim_{\norm[Î”_n] â†’ 0}  âˆ‘_{j = 0}^{n - 1} \good{X_{t_{j}}} \okay{Y^{t_{j+1}}} Î”B_j ,
			\stopformula
			provided that the limit exists in probability.

		% \item  Now, for any stochastic process \m{Z(t) = âˆ‘_{k = 1}^n \good{X_t^{(k)}} \okay{Y^t_{(k)}}} we extend the definition by linearity.

		% \item  This is well-defined \cite[short][HwangKuoSaitÃ´Zhai2016].
		%\m{âˆ«_0^T Z(t) \d B_t = âˆ‘_{k = 1}^n âˆ«_0^T Z(t) X_t^{(k)} Y^t_{(k)} \d B_t}.
		% \startformula
		% 	âˆ«_0^T Z(t) \d B_t = âˆ‘_{k = 1}^n âˆ«_0^T \good{X_t^{(k)}} \okay{Y^t_{(k)}} \d B_t
		% \stopformula

	\stopitemize
\stopslide

\startslide [title={A simple example}]

	\startitemize [4]

		\item  	In the following, \m{\lim} is the limit in \m{L^2}.
			\startformula \startalign
				\NC  âˆ«_0^t B_T \d B_t
					\NC =  âˆ«_0^t (\good{B_t} + \okay{(B_T - B_t)}) \d B_t
					    =  \good{âˆ«_0^t B_t \d B_t}  +  \okay{âˆ«_0^t (B_T - B_t) \d B_t}
				\NR \NC
					\NC =  \good{\lim âˆ‘_{j = 0}^{n - 1} B_{t_j} Î” B_j}
						+  \okay{\lim âˆ‘_{j = 0}^{n - 1} (B_T - B_{t_{j + 1}}) Î” B_j}
				\NR \NC
					\NC =  \lim âˆ‘_{j = 0}^{n - 1} \brnd[B_T - Î” B_j] Î” B_j
				\NR \NC
					\NC =  B_T \lim âˆ‘_{j = 0}^{n - 1} Î” B_j - \lim âˆ‘_{j = 0}^{n - 1} (Î” B_j)^2
					    =  B_T B_t - t
			\stopalign \stopformula

		\item  Note that \m{ğ”¼(B_T B_t - t) = 0}.

		\item  In general, \m{ğ”¼ âˆ«_0^t Z(s) \d B_s = 0}. \good{\smile}
	\stopitemize
\stopslide

\startslide [title={The near-martingale property}]

	\startitemize [4]

		\item  Question: What are the analogues of the martingale property and the Markov property?

		% \item  Answer for martingales: near-martingales \cite[short][KuoSaeTangSzozda2012].

		\item  Example: \m{ğ”¼(B_T B_t - t âˆ£ â„±_s) = B_s^2 - s â‰  B_T B_s - s}. \frown

			But \m{ğ”¼(B_T B_s - s âˆ£ â„±_s) = B_s^2 - s}. \smile

		\item  Let \m{Z(t)} be a process such that \m{ğ”¼\abs[Z(t)] < âˆ \ âˆ€ t}, and \m{0 â‰¤ s â‰¤ t â‰¤ T}. Then \m{Z(t)} is called a \important{near-martingale} if \m{ğ”¼(Z(t) âˆ£ â„±_s) = ğ”¼(Z(s) âˆ£ â„±_s)}.

	\stopitemize

	\starttheorem [title={\cite[short][KuoSaeTangSzozda2012]}]
		Let \m{f} and \m{Ï•} be continuous functions on \m{â„}. Under integrability conditions, the processes \m{X_{\argdotsub} = âˆ«_0^{\argdotsup} f(B_t) Ï•(B_T - B_t) \d B_t} and \m{Y^{\argdotsup} = âˆ«_{\argdotsub}^T f(B_t) Ï•(B_T - B_t) \d B_t} are near-martingales.
	\stoptheorem

	\starttheorem [title={\cite[short][HwangKuoSaitÃ´Zhai2017]}]
		Let \m{Z(\argdotmid)} be a stochastic process bounded in \m{L^1}, and \m{X_{\argdotsub} = ğ”¼(Z(\argdotmid) âˆ£ â„±_{\argdotsub})}. Then \m{X_{\argdotsub}} is a martingale if and only if \m{Z(\argdotmid)} is a near-martingale.
	\stoptheorem
\stopslide

\stopmode

\stopsection

\stopbodymatter



%%%%%%%%%%%%%%%
% Back matter %
%%%%%%%%%%%%%%%

\startbackmatter

\setupbackgrounds [page] [
	background={color,backgraphics,foreground},
	backgroundcolor=\getvariable{document}{color-background-0}]
\startcolor [\getvariable{document}{color-foreground-0}]    % text color

\startsubject [title={Appendix}, reference=sub:appendix]

\page

\startsubsubject [title={History of Probability Theory}, reference=sec:history]
\startmode [presentation]

\startslide [title={History: Probability theory}]
	
	\startitemize [m]
		
		\item  1564: Gerolamo Cardano published \emph{Liber de ludo aleae} (Book on Games of Chance).

			% Before then, there were many aspects of chance phenomena noted, but not dealt with systematically.
		
		\item  1654: Pascal and Fermat corresponded about the \emph{problem of points} floated by the gambler Chevalier de MÃ©rÃ©. This is understood to be the origin of systematic study of probability.

		\item  1657: Christiaan Huygens published a book titled \emph{De Ratiociniis in Ludo Aleae}.

		\item  1800s: Pierre Laplace completed what is today considered the classic interpretation.
		
		\item  Applications in annuities, statistics of mortality, life insurance, assessing evidence, etc.

		% \item  Classical interpretation: Initial considerations were discrete (combinatorial), but later analytical was taken into accont.

		\item  1904: Henri Lebesgue published what is now knows as the Lebesgue integral.

			The idea was generalized into abstract integrals (over arbitrary spaces).

		\item  1933: Andrey Kolmogorov published \emph{Foundations of the Theory of Probability}.

			This axiomatic approach unified the theories of discrete and continuous probability.

			% This established probability theory as a field of study within mathematics, in particular, analysis.

	\stopitemize
\stopslide

\startslide [title={History: Brownian motion}]
	
	\startitemize [m]
		
		\item  1827: Discovered by the biologist Robert Brown while studying pollen particles floating in water in the microscope.

		\item  1900: Louis Bachelier used Brownian motion to model financial markets in his PhD thesis \emph{The theory of speculation}.

		\item  1905: Albert Einstein tried to explain Brownian motion using a probabilistic model for diffusion transport.

		\item  1923: Norbert Wiener rigorously constructed the Brownian motion, proving its existence.

		\item  1944: Kiyosi ItÃ´ published his integral w.r.t. a Brownian motion.

		\item  1973: Black and Scholes used Brownian motion and the ItÃ´ integral to model the stock market.
	\stopitemize
\stopslide

\stopmode
\stopsubsubject


\startmode [presentation]
\startslide

	\startalign [middle]

		\blank[4*line]

		{\tfd Thank you!}

	\stopalign
\stopslide
\stopsubject

\startslide [title={Bibliography}]
	\placelistofpublications
\stopslide
\stopmode
\stopbackmatter

\stoptext
